= Knowledge base
:toc:
:toc-placement!:

This is an AsciiDoc footnote:[https://powerman.name/doc/asciidoc] footnote:[https://asciidoc.org/userguide.html] acting as a knowledge base, of the background research being done while developing link:README.md[forward].

toc::[]


== Big Design Up Front - Wikipedia footnote:[https://en.wikipedia.org/wiki/Big_Design_Up_Front]

> argue that BDUF is poorly adaptable to changing requirements 

> the needs of the business evolve at a pace faster than large projects are completed in - making the Big Design outdated by the time the system is completed. 

> If the cost of planning is greater than the cost of fixing then time spent planning is wasted. 

> run-time fixes are vastly more costly than design fixes 

> Improving software with the benefit of user feedback is generally less expensive than trying to anticipate and document every aspect of a system with BDUF 

> in most projects there is a significant lack of comprehensive written (or even well known) requirements. So in BDUF a lot of assumptions are made that later prove to be false 

> much easier to fix a requirements bug in the requirements phase than to fix that same bug in the implementation phase 

== Analysis paralysis - Wikipedia footnote:[https://en.wikipedia.org/wiki/Analysis_paralysis]

> exceedingly long phases of project planning, requirements gathering, program design, and data modeling, which can create little or no extra value

> Analysis paralysis can also arise from extensive experience or expertise, which serves to increase the number of options and considerations that appear at every decision point.

== Waterfall model - Wikipedia footnote:[https://en.wikipedia.org/wiki/Waterfall_model#Model]

> However he also felt it had major flaws stemming from the fact that testing only happened at the end of the process, which he described as being "risky and invites failure".

> Time spent early in the software production cycle can reduce costs at later stages

> a problem found in the early stages (such as requirements specification) is cheaper to fix than the same bug found later on in the process (by a factor of 50 to 200)

> emphasis on documentation

> new team members or even entirely new teams should be able to familiarise themselves by reading the documents

> In less thoroughly designed and documented methodologies, knowledge is lost if team members leave before the project is completed

> the model itself progresses linearly through discrete, easily understandable and explainable phases and thus is easy to understand

> Royce also advocated large quantities of documentation, doing the job "twice if possible"

> Designers may not be aware of future difficulties

> better to revise the design than persist in a design that does not account for any newly discovered constraints, requirements, or problems

== Cleanroom software engineering - Wikipedia footnote:[https://en.wikipedia.org/wiki/Cleanroom_software_engineering]

> intended to produce software with a certifiable level of reliability

> defect prevention, rather than defect removal

> Software development based on formal methods

> Verification that the design correctly implements the specification is performed through team review, often with software tool support

== Formal methods - Wikipedia footnote:[https://en.wikipedia.org/wiki/Formal_methods]

> Specification

> description of the system to be developed

> formalising system requirements

> Development

> If the formal specification is in axiomatic semantics, the preconditions and postconditions of the specification may become assertions in the executable code

> Verification

> prove that a formal model of a system implementation satisfies its specification

> Human-directed proof

> a desire to understand the system better

> Automated proof

> Critics note that some of those systems are like oracles: they make a pronouncement of truth, yet give no explanation of that truth. There is also the problem of "verifying the verifier";

> For sequential software, examples of formal methods include the B-Method, the specification languages used in automated theorem proving, RAISE, and the Z notation.

> In functional programming, property-based testing has allowed the mathematical specification and testing (if not exhaustive testing) of the expected behaviour of individual functions.

> For concurrent software and systems, Petri nets, process algebra, and finite state machines

> SPARK Ada

> TLA+

== Formal specification - Wikipedia footnote:[https://en.wikipedia.org/wiki/Formal_specification]

> formal specifications are mathematically based

> describe a system

> formal in the sense that they have a syntax, their semantics fall within one domain

> Given such a specification, it is possible to use formal verification techniques to demonstrate that a system design is correct with respect to its specification

> This allows incorrect system designs to be revised before any major investments have been made into an actual implementation

> Formal specifications describe what a system should do, not how the system should do it.

> good specification must have some of the following attributes: adequate, internally consistent, unambiguous, complete, satisfied, minimal

> A design (or implementation) cannot ever be declared “correct” on its own. It can only ever be “correct with respect to a given specification”. Whether the formal specification correctly describes the problem to be solved is a separate issue

> Implementations of formal specifications will differ depending on what kind of system they are attempting to model

> State-based specification[3]
  behavior based on system states
  series of sequential steps, (e.g. a financial transaction)
  languages such as Z, VDM or B rely on this paradigm

> Transition-based specification[3]
  behavior based on transitions from state-to-state of the system
  best used with a reactive system

> Functional specification[3]
  specify a system as a structure of mathematical functions
  OBJ, ASL, PLUSS, LARCH, HOL or PVS rely on this paradigm

== Formal verification - Wikipedia footnote:[https://en.wikipedia.org/wiki/Formal_verification]

> formal verification is the act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification

> Examples of mathematical objects often used to model systems are: finite state machines

> One approach and formation is model checking, which consists of a systematically exhaustive exploration of the mathematical model

> this is possible for finite models

> exploring all states

> Another approach is deductive verification

> It consists of generating from the system and its specifications (and possibly other annotations) a collection of mathematical proof obligations

> proof assistants (interactive theorem provers) (such as HOL, ACL2, Isabelle, Coq or PVS)

> requires the user to understand in detail why the system works correctly

> A promising type-based verification approach is dependently typed programming

> techniques can be sound, meaning that the verified properties can be logically deduced from the semantics, or unsound, meaning that there is no such guarantee

> A sound technique yields a result only once it has searched the entire space of possibilities

> An example of an unsound technique is one that searches only a subset of the possibilities, for instance only integers up to a certain number, and give a "good-enough" result

> Techniques can also be decidable, meaning that their algorithmic implementations are guaranteed to terminate with an answer, or undecidable, meaning that they may never terminate

> Verification: "Have we made what we were trying to make?", i.e., does the product conform to the specifications?

> Validation: "Are we trying to make the right thing?", i.e., is the product specified to the user's actual needs?

> use in the software industry is still languishing

